{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import fitz  # PyMuPDF\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка страницы 132\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/IDE/repository/liquid_vapor_database')\n",
    "from src.pdf_image_extractor import PDFImageExtractor\n",
    "from src.pdf_page_processor import Page\n",
    "\n",
    "\n",
    "# Путь к PDF файлу и путь к Tesseract\n",
    "NUM_PAGE = 132\n",
    "pdf_path = 'C:/IDE/repository/liquid_vapor_database/data/Kogan_1.pdf'\n",
    "tesseract_path = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "image = PDFImageExtractor(pdf_path, tesseract_path, images_folder=f'pdf_data/page_{NUM_PAGE}')        \n",
    "page = Page(NUM_PAGE, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PDFImageExtractor' object has no attribute 'extract_images_from_pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m tesseract_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Program Files/Tesseract-OCR/tesseract.exe\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m extractor \u001b[38;5;241m=\u001b[39m PDFImageExtractor(pdf_path, tesseract_path)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_images_from_pdf\u001b[49m(start_page\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m131\u001b[39m, end_page\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m132\u001b[39m)\n\u001b[0;32m     12\u001b[0m extractor\u001b[38;5;241m.\u001b[39mextract_text_from_images(start_page\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m131\u001b[39m, end_page\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m132\u001b[39m)\n\u001b[0;32m     13\u001b[0m column_names_area \u001b[38;5;241m=\u001b[39m ColumnLineDetector( \u001b[38;5;66;03m# переименовать класс в column_names_area\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_images\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpage_132_processed.png\u001b[39m\u001b[38;5;124m'\u001b[39m, extractor\u001b[38;5;241m.\u001b[39mtext, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdetect_column_names_area()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PDFImageExtractor' object has no attribute 'extract_images_from_pdf'"
     ]
    }
   ],
   "source": [
    "from pdf_image_extractor import PDFImageExtractor\n",
    "from column_names_detector import ColumnLineDetector\n",
    "from column_values_detector import ColumnValuesDetector\n",
    "from group_grouper import GaussianCurveGrouper\n",
    "\n",
    "# Путь к PDF файлу и путь к Tesseract\n",
    "pdf_path = 'Kogan_1.pdf'\n",
    "tesseract_path = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "extractor = PDFImageExtractor(pdf_path, tesseract_path)\n",
    "\n",
    "extractor.extract_images_from_pdf(start_page=131, end_page=132)\n",
    "extractor.extract_text_from_images(start_page=131, end_page=132)\n",
    "column_names_area = ColumnLineDetector( # переименовать класс в column_names_area\n",
    "    'extracted_images\\page_132_processed.png', extractor.text, debug=True).detect_column_names_area()\n",
    "column_values_area = ColumnValuesDetector( # переименовать класс в column_values_area\n",
    "    'extracted_images\\page_132_processed.png', extractor.text, debug=True).detect_column_values_area()\n",
    "\n",
    "\n",
    "grouper = GaussianCurveGrouper(\n",
    "    hystogram_data='histogram_data.csv',\n",
    "    ocr_text_path=\"extracted_images/extracted_text.txt\", \n",
    "    regex_pattern=r\"([NnеНЕмт№]\\s?\\d*\\.?\\d*\\s?.*?\\[.*?\\])\"\n",
    "    )\n",
    "grouped_data = grouper.group_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[400.0,\n",
       "  450.0,\n",
       "  550.0,\n",
       "  600.0,\n",
       "  650.0,\n",
       "  700.0,\n",
       "  750.0,\n",
       "  800.0,\n",
       "  850.0,\n",
       "  900.0,\n",
       "  1050.0,\n",
       "  1300.0,\n",
       "  1450.0,\n",
       "  1500.0],\n",
       " [2100.0, 2200.0, 2250.0, 2350.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[400.0,\n",
       "  450.0,\n",
       "  550.0,\n",
       "  600.0,\n",
       "  650.0,\n",
       "  700.0,\n",
       "  750.0,\n",
       "  800.0,\n",
       "  850.0,\n",
       "  900.0,\n",
       "  1050.0,\n",
       "  1300.0,\n",
       "  1450.0,\n",
       "  1500.0],\n",
       " [2100.0, 2200.0, 2250.0, 2350.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_matching_lines(filename, pattern):\n",
    "    # Счётчик строк, соответствующих шаблону\n",
    "    count = 0\n",
    "\n",
    "    # Открываем файл и читаем его построчно\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Проверяем, соответствует ли строка шаблону\n",
    "            if re.search(pattern, line):\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "def group_data_by_gaussian_curves(filename, n_curves):\n",
    "    MIN_DISTANCE = 500\n",
    "    AGGREGATION_STEP = 50\n",
    "    # Загрузка данных\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Создание нового столбца для агрегированных значений\n",
    "    df['Center_Y_Aggregated'] = (df['Center_Y'] // AGGREGATION_STEP) * AGGREGATION_STEP\n",
    "\n",
    "    # Подсчет количества вхождений для каждой агрегированной категории\n",
    "    aggregated_counts = df['Center_Y_Aggregated'].value_counts().sort_index()    \n",
    "\n",
    "    # Поиск наибольших точек    \n",
    "    point = aggregated_counts.sort_values(ascending=False).index[0]\n",
    "    other_points = [value for value in aggregated_counts.sort_values(ascending=False).index if abs(value - point) > MIN_DISTANCE]\n",
    "    points = [point, *other_points]\n",
    "    valid_points = points[:n_curves]\n",
    "\n",
    "    if len(valid_points) < n_curves:\n",
    "        raise ValueError(\"Не удалось найти достаточное количество точек, удовлетворяющих условиям.\")\n",
    "\n",
    "    # Функция для гауссианы\n",
    "    def gaussian(x, mu, sigma, height):\n",
    "        return height * np.exp(-np.power(x - mu, 2.) / (2 * np.power(sigma, 2.)))\n",
    "\n",
    "    # Разделение значений на группы\n",
    "    groups = [[] for _ in range(n_curves)]\n",
    "    for idx in aggregated_counts.index:\n",
    "        gauss_values = [gaussian(idx, point, 500, aggregated_counts[point]) for point in valid_points]\n",
    "        assigned_group = np.argmax(gauss_values)\n",
    "        groups[assigned_group].append(idx)\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "# Регулярное выражение, заданное в запросе\n",
    "general_regex = r\"([NnеНЕмт№]\\s?\\d*\\.?\\d*\\s?.*?\\[.*?\\])\"\n",
    "grouped_data = group_data_by_gaussian_curves(\n",
    "    'histogram_data.csv', \n",
    "    count_matching_lines(\"extracted_images/extracted_text.txt\", general_regex))\n",
    "# Повторное тестирование функции с исправлением\n",
    "\n",
    "grouped_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[300.0,\n",
       "  400.0,\n",
       "  450.0,\n",
       "  500.0,\n",
       "  600.0,\n",
       "  700.0,\n",
       "  750.0,\n",
       "  800.0,\n",
       "  850.0,\n",
       "  1050.0,\n",
       "  1150.0,\n",
       "  1250.0,\n",
       "  1300.0,\n",
       "  1450.0,\n",
       "  1500.0],\n",
       " [2100.0, 2200.0, 2250.0, 2300.0, 2350.0]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def group_data_by_gaussian_curves(filename, n_curves):\n",
    "    MIN_DISTANCE = 500\n",
    "    AGGREGATION_STEP = 50\n",
    "    # Загрузка данных\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Создание нового столбца для агрегированных значений\n",
    "    df['Center_Y_Aggregated'] = (df['Center_Y'] // AGGREGATION_STEP) * AGGREGATION_STEP\n",
    "\n",
    "    # Подсчет количества вхождений для каждой агрегированной категории\n",
    "    aggregated_counts = df['Center_Y_Aggregated'].value_counts().sort_index()    \n",
    "\n",
    "    # Поиск наибольших точек    \n",
    "    point = aggregated_counts.sort_values(ascending=False).index[0]\n",
    "    other_points = [value for value in aggregated_counts.sort_values(ascending=False).index if abs(value - point) > MIN_DISTANCE]\n",
    "    points = [point, *other_points]\n",
    "    valid_points = points[:n_curves]\n",
    "\n",
    "    if len(valid_points) < n_curves:\n",
    "        raise ValueError(\"Не удалось найти достаточное количество точек, удовлетворяющих условиям.\")\n",
    "\n",
    "    # Функция для гауссианы\n",
    "    def gaussian(x, mu, sigma, height):\n",
    "        return height * np.exp(-np.power(x - mu, 2.) / (2 * np.power(sigma, 2.)))\n",
    "\n",
    "    # Разделение значений на группы\n",
    "    groups = [[] for _ in range(n_curves)]\n",
    "    for idx in aggregated_counts.index:\n",
    "        gauss_values = [gaussian(idx, point, 500, aggregated_counts[point]) for point in valid_points]\n",
    "        assigned_group = np.argmax(gauss_values)\n",
    "        groups[assigned_group].append(idx)\n",
    "\n",
    "    return groups\n",
    "\n",
    "# Повторное тестирование функции с исправлением\n",
    "grouped_data_fixed = group_data_by_gaussian_curves('histogram_data.csv', 2)\n",
    "grouped_data_fixed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
